{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5227,
     "status": "ok",
     "timestamp": 1622623085840,
     "user": {
      "displayName": "Minutes Craft IT",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GguqRJ_T5Uada5SwMv2-8Wv6xk0yrhjJy2eN1FxLA=s64",
      "userId": "05748800807703982349"
     },
     "user_tz": -180
    },
    "id": "P2VIcyqpTF6i"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim  \n",
    "import pandas as pd\n",
    "from data_processing import preprocessing_german, preprocessing_adult \n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import accuracy_score \n",
    "from utils import Logger, DatasetLoader\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from model import MLP\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 224,
     "status": "ok",
     "timestamp": 1622623111429,
     "user": {
      "displayName": "Minutes Craft IT",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GguqRJ_T5Uada5SwMv2-8Wv6xk0yrhjJy2eN1FxLA=s64",
      "userId": "05748800807703982349"
     },
     "user_tz": -180
    },
    "id": "PIMEXBIwztQ7"
   },
   "outputs": [],
   "source": [
    "def train_test_split2(X, y, S, test_size=0.3):\n",
    "    split_size = int(X.shape[0] * test_size)\n",
    "    X_test, y_test, s_test = X[0:split_size, :], y[0:split_size], S[0:split_size]\n",
    "    X_train, y_train, s_train  = X[split_size+1:, :], y[split_size+1:], S[split_size+1:]\n",
    "    print(split_size)\n",
    "    print(X_train.shape, y_train.shape)\n",
    "    return torch.from_numpy(X_train), torch.from_numpy(X_test), torch.from_numpy(y_train), torch.from_numpy(y_test), torch.from_numpy(s_train), torch.from_numpy(s_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the German dataset and preprocess it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 714,
     "status": "ok",
     "timestamp": 1622623116745,
     "user": {
      "displayName": "Minutes Craft IT",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GguqRJ_T5Uada5SwMv2-8Wv6xk0yrhjJy2eN1FxLA=s64",
      "userId": "05748800807703982349"
     },
     "user_tz": -180
    },
    "id": "lkZ95n4459sp",
    "outputId": "fd7a1e34-d46f-4328-ee63-f3b52a39e55e"
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"./dataset/german.data.csv\")\n",
    "#test_data = pd.read_csv(\"./dataset/german.test.csv\")\n",
    "n_data = 32561 \n",
    "X, y, S, data = preprocessing_german(train_data) \n",
    "\n",
    "X_train, X_test, y_train, y_test, S_train, S_test =  train_test_split2(X, y, S, test_size=0.3)\n",
    "X = torch.from_numpy(X)\n",
    "y = torch.from_numpy(y)\n",
    "S = torch.from_numpy(S)  \n",
    "DATA_SET_NAME = \"German\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Adult Income dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''train_data = pd.read_csv(\"./dataset/adult.data.csv\")\n",
    "#test_data = pd.read_csv(\"./dataset/german.test.csv\")\n",
    "n_data = 32561 \n",
    "X, y, S, data = preprocessing_adult(train_data, n_data) \n",
    "\n",
    "X_train, X_test, y_train, y_test, S_train, S_test =  train_test_split2(X, y, S, test_size=0.3)\n",
    "X = torch.from_numpy(X)\n",
    "y = torch.from_numpy(y)\n",
    "S = torch.from_numpy(S)  \n",
    "DATA_SET_NAME = \"Adult\"'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 332,
     "status": "ok",
     "timestamp": 1622623120422,
     "user": {
      "displayName": "Minutes Craft IT",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GguqRJ_T5Uada5SwMv2-8Wv6xk0yrhjJy2eN1FxLA=s64",
      "userId": "05748800807703982349"
     },
     "user_tz": -180
    },
    "id": "AzZcRXa0y5ZK",
    "outputId": "7a25e8b3-dccc-4f2b-f7fd-92b02eea2227"
   },
   "outputs": [],
   "source": [
    "n_feature = X.shape[1]\n",
    "latent_dim = 8 # latent dim space as in LAFTR\n",
    "logger = Logger('AutoEncoder', DATA_SET_NAME)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 258,
     "status": "ok",
     "timestamp": 1622623130028,
     "user": {
      "displayName": "Minutes Craft IT",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GguqRJ_T5Uada5SwMv2-8Wv6xk0yrhjJy2eN1FxLA=s64",
      "userId": "05748800807703982349"
     },
     "user_tz": -180
    },
    "id": "IDGaT3MEnmk1"
   },
   "outputs": [],
   "source": [
    "# prepare training and testing data\n",
    "training_data = DatasetLoader(X, y, S)\n",
    "test_data = DatasetLoader(X_test, y_test, S_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 338,
     "status": "ok",
     "timestamp": 1622623133614,
     "user": {
      "displayName": "Minutes Craft IT",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GguqRJ_T5Uada5SwMv2-8Wv6xk0yrhjJy2eN1FxLA=s64",
      "userId": "05748800807703982349"
     },
     "user_tz": -180
    },
    "id": "xqGGi6qg0841"
   },
   "outputs": [],
   "source": [
    "has_gpu = torch.cuda.is_available() \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# batch size\n",
    "batch_size = 64*2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods to train a neural network based classifier to assess the fairness performances of a representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "confusion_metric_results = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Jo6ajdn-tc5"
   },
   "source": [
    "### Train the auto encoder, classifier, adversary and compare the fairness performances of learned representation on some classsical ML algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are using our [own](./fairness_metrics.py) implementation of fairness metrics [fairlearn](https://fairlearn.org/v0.7.0/api_reference/fairlearn.metrics.html) package can be used as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fairlearn.metrics import equalized_odds_difference, demographic_parity_difference, false_negative_rate_difference\n",
    "from sklearn.metrics import accuracy_score \n",
    "from fairness_metrics import cross_val_fair_scores, statistical_parity_score, confusion_matrix_score\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.model_selection import cross_val_score, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import DemParModel, EqualOddModel, EqualOppModel\n",
    "from trainer import Trainer, train_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1622623147889,
     "user": {
      "displayName": "Minutes Craft IT",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GguqRJ_T5Uada5SwMv2-8Wv6xk0yrhjJy2eN1FxLA=s64",
      "userId": "05748800807703982349"
     },
     "user_tz": -180
    },
    "id": "2vJ9JTwFsS0O"
   },
   "outputs": [],
   "source": [
    "data_loader = DataLoader(training_data, batch_size=batch_size, shuffle=True) \n",
    "test_data_loader = DataLoader(test_data, batch_size=batch_size, shuffle=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train a model on the original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "\n",
    "kfold = KFold(n_splits=5)\n",
    "clr = LogisticRegression(max_iter=1000) \n",
    "\n",
    "acc_, dp_, eqodd_, eopp_ = cross_val_fair_scores(clr, X_train.cpu().detach().numpy(), y_train.cpu().detach().numpy(), kfold, S_train.cpu().detach().numpy())  \n",
    "results[\"Unfair\"] = ([np.mean(acc_), np.mean(dp_), np.mean(eqodd_), np.mean(eopp_)], [np.std(acc_), np.std(dp_), np.std(eqodd_), np.std(eopp_)]) \n",
    " \n",
    "print(\"Accuracy:{:.3f} (+/-) {:.3f} \".format(np.mean(acc_), np.std(acc_))) \n",
    "print(\"demographic parity:{:.3f} (+/-) {:.3f} \".format(np.mean(dp_), np.std(dp_)))  \n",
    "print(\"equlized odd score:{:.3f} (+/-){:.3f} \".format(np.mean(eqodd_), np.std(eqodd_)))\n",
    "print(\"equal opportunity score:{:.3f} (+/-){:.3f} \".format(np.mean(eopp_), np.std(eopp_)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### learn fair representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DemParModel(n_feature=n_feature, latent_dim=15, class_weight=1, recon_weight=0, adv_weight=1, hidden_layers={'class': 20, 'ae': 20, 'avd': 20}) \n",
    "trainer = Trainer(model, data_loader, DATA_SET_NAME, \"LFR\")\n",
    "parts = [\"autoencoder\", \"classifier\", \"adversary\"]\n",
    "trainer.train_privacy(parts, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We test the learned mapping function on test data and measure the accuracy and fairness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=5)\n",
    "X_transformed = model.transform(X_test.to(device))  \n",
    "clr = LogisticRegression(max_iter=1000)  \n",
    "acc_, dp_, eqodd_, eopp_ = cross_val_fair_scores(clr, X_transformed.cpu().detach().numpy(), y_test.cpu().detach().numpy(), kfold, S_test.cpu().detach().numpy())\n",
    "scores_ = [np.mean(acc_), np.mean(dp_), np.mean(eqodd_), np.mean(eopp_)]  \n",
    "std_ = [np.std(acc_), np.std(dp_), np.std(eqodd_), np.std(eopp_)]  \n",
    "results[model.name] = (scores_, std_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the results to compare fairness and accuracy on the original dataset and the learned fair representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=2, nrows=1, figsize=(11,4))\n",
    "x = np.arange(len(results))\n",
    "width = .4\n",
    "plot_names, plot_values, sdt_values = [], [], []\n",
    "for name in results:\n",
    "    plot_names.append(name)\n",
    "    metrics, stds = results[name]\n",
    "    plot_values.append(metrics)\n",
    "    sdt_values.append(stds)\n",
    "\n",
    "\n",
    "plot_values = np.array(plot_values)\n",
    "sdt_values = np.array(sdt_values)\n",
    "#print(plot_values)\n",
    "ax[0].bar(x, plot_values[:, 0], width, yerr=sdt_values[:, 0], label='Accuracy')\n",
    "ax[1].bar(x-width/3, plot_values[:, 1], width/3,  yerr=sdt_values[:, 1], label='$\\Delta_{DP}$')\n",
    "ax[1].bar(x, plot_values[:, 2], width/3, label='$\\Delta_{EOD}$')\n",
    "ax[1].bar(x+width/3, plot_values[:, 3], width/3, label='$\\Delta_{EOP}$')\n",
    "\n",
    "for i in [0,1]:\n",
    "    ax[i].set_xticks(x)  \n",
    "    ax[i].set_xticklabels(plot_names) \n",
    "    ax[i].legend()\n",
    "fig.tight_layout()\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "german_stacked_learn_fair_representation.ipynb",
   "toc_visible": true,
   "version": ""
  },
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
